{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import functools\n",
    "\n",
    "from src.display import showarray\n",
    "from src.mask import MaskGenerator\n",
    "from src.datagen import DatasetFillGenerator\n",
    "from src.augmenters import masked_channel_augmenter\n",
    "from src.builders.unet import UNETBuilder\n",
    "from src.loss import MaskedMAE, MaskedGaussedSobelMAE, GaussedSobelMAE, CombinedLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msbartekt\u001b[0m (\u001b[33mput_dl_team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230122_125438-nbaaqp3a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/put_dl_team/cv3-ii-ae-unet/runs/nbaaqp3a\" target=\"_blank\">happy-meadow-29</a></strong> to <a href=\"https://wandb.ai/put_dl_team/cv3-ii-ae-unet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/put_dl_team/cv3-ii-ae-unet\" target=\"_blank\">https://wandb.ai/put_dl_team/cv3-ii-ae-unet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/put_dl_team/cv3-ii-ae-unet/runs/nbaaqp3a\" target=\"_blank\">https://wandb.ai/put_dl_team/cv3-ii-ae-unet/runs/nbaaqp3a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 16,\n",
    "  \"batch_size\": 16,\n",
    "  \"mask_gen_degree\": \"HEAVY\",\n",
    "  \"mask_gen_min_width\": 5,\n",
    "  \"mask_gen_max_width\": 12,\n",
    "  \"learning_rate\": 0.001\n",
    "}\n",
    "model_params = {\n",
    "  \"n_filters\": 32,\n",
    "  \"n_layers\": 3,\n",
    "  \"n_convs\": 1,\n",
    "  \"activation\": \"elu\",\n",
    "  \"dropout_rate\": 0.4,\n",
    "}\n",
    "loss_dict = {\n",
    "  \"masked_mae\": MaskedMAE(),\n",
    "  \"masked_gaussed_sobel_mae\": MaskedGaussedSobelMAE(),\n",
    "  \"gaussed_sobel_mae\": GaussedSobelMAE(),\n",
    "  \"mae\": tf.keras.losses.MeanAbsoluteError(),\n",
    "}\n",
    "loss_weights = {\n",
    "  \"masked_mae\": 1.0,\n",
    "  \"masked_gaussed_sobel_mae\": 1.0,\n",
    "  \"gaussed_sobel_mae\": 1.0,\n",
    "  \"mae\": 1.0,\n",
    "}\n",
    "\n",
    "loss_config = {key: (loss_fn, loss_weights[key]) for key, loss_fn in loss_dict.items()}\n",
    "\n",
    "config.update({f\"unet_{key}\": val for key, val in model_params.items()})\n",
    "config.update({f\"loss_{key}_weight\": val for key, val in loss_weights.items()})\n",
    "wandb.init(project=\"cv3-ii-ae-unet\", entity=\"put_dl_team\", config=config)\n",
    "\n",
    "IMAGE_SIZE = (256, 256)\n",
    "CHANNELS = 4\n",
    "BATCH_SIZE = wandb.config[\"batch_size\"]\n",
    "\n",
    "MASK_GEN_PARAM = {\n",
    "    \"degree\": wandb.config[\"mask_gen_degree\"],\n",
    "    \"min_width\": wandb.config[\"mask_gen_min_width\"],\n",
    "    \"max_width\": wandb.config[\"mask_gen_max_width\"],\n",
    "}\n",
    "\n",
    "mask_generator = MaskGenerator(*IMAGE_SIZE, CHANNELS-1, **MASK_GEN_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2188 files belonging to 1 classes.\n",
      "Using 1970 files for training.\n",
      "Using 218 files for validation.\n"
     ]
    }
   ],
   "source": [
    "def scale(tensor: tf.Tensor, divisor: float = 255.0) -> tf.Tensor:\n",
    "    return tensor / divisor\n",
    "\n",
    "def recast_to_image(tensor: tf.Tensor) -> np.ndarray:\n",
    "    return tf.cast(tensor[:, :, :3] * 255, tf.uint8).numpy()\n",
    "\n",
    "\n",
    "ds_train, ds_valid = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"../data/1-8size\", label_mode=None, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
    "    shuffle=True, seed=42, validation_split=0.1, subset=\"both\",\n",
    ")\n",
    "ds_train = ds_train.map(scale)\n",
    "ds_valid = ds_valid.map(scale)\n",
    "\n",
    "for batch in ds_valid.take(1):\n",
    "    showcase_images = batch[:5]\n",
    "\n",
    "\n",
    "class ImageFillCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, showcase_images, mask_generator):\n",
    "        self.model = model\n",
    "        self.masked_images, self.showcase_images = masked_channel_augmenter(showcase_images, mask_generator)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        nn_filled = self.model.predict(self.masked_images)\n",
    "        all_joint = []\n",
    "        for i in range(5):\n",
    "            masked = recast_to_image(self.masked_images[i])\n",
    "            original_image = recast_to_image(self.showcase_images[i])\n",
    "            filled_image = recast_to_image(nn_filled[i])\n",
    "            joint = np.concatenate([masked, original_image, filled_image], axis=1)\n",
    "            all_joint.append(joint)\n",
    "        all_joint = np.concatenate(all_joint, axis=0)\n",
    "        wandb.log({\"sample_fill\": wandb.Image(all_joint)})\n",
    "\n",
    "dataset_image_augmenter = functools.partial(masked_channel_augmenter, mask_generator=mask_generator)\n",
    "\n",
    "np.random.seed(42)\n",
    "train_generator = DatasetFillGenerator(ds_train, IMAGE_SIZE, CHANNELS, dataset_image_augmenter)\n",
    "valid_generator = DatasetFillGenerator(ds_valid, IMAGE_SIZE, CHANNELS, dataset_image_augmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 32  1184        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 32  0           ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 64  18496       ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64, 64, 64)   0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 64, 64, 128)  73856       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0          ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32, 32, 128)  0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 128)  147584      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 64, 64, 128)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 256)  0           ['up_sampling2d[0][0]',          \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 128)  295040      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 64)   73792       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 64  0          ['conv2d_5[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 12  0           ['up_sampling2d_1[0][0]',        \n",
      "                                8)                                'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 128, 128, 64  73792       ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 128, 32  18464       ['conv2d_6[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 32  0          ['conv2d_7[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 64  0           ['up_sampling2d_2[0][0]',        \n",
      "                                )                                 'conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 256, 256, 32  18464       ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 256, 256, 4)  132         ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 720,804\n",
      "Trainable params: 720,804\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IM_SHAPE = (*IMAGE_SIZE, CHANNELS)\n",
    "builder = UNETBuilder(IM_SHAPE, IM_SHAPE, **model_params)\n",
    "model = builder.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CombinedLoss(loss_config)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=wandb.config[\"learning_rate\"]),\n",
    "    loss=loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "124/124 [==============================] - ETA: 0s - loss: 0.2219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230122_125438-nbaaqp3a\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230122_125438-nbaaqp3a\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230122_125438-nbaaqp3a\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 256, 256, 4) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 256, 256, 4) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49mwandb\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m\"\u001b[39;49m], validation_data\u001b[39m=\u001b[39;49mvalid_generator, callbacks\u001b[39m=\u001b[39;49m[wandb\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mWandbCallback(), ImageFillCallback(model, showcase_images, mask_generator)])\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[4], line 26\u001b[0m, in \u001b[0;36mImageFillCallback.on_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_epoch_end\u001b[39m(\u001b[39mself\u001b[39m, epoch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> 26\u001b[0m     nn_filled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmasked_images)\n\u001b[0;32m     27\u001b[0m     all_joint \u001b[39m=\u001b[39m []\n\u001b[0;32m     28\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filezhi0dtv1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 2041, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 2027, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 2015, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py\", line 1983, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 216, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Layer \"model\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 256, 256, 4) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 256, 256, 4) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=wandb.config[\"epochs\"], validation_data=valid_generator, callbacks=[wandb.keras.WandbCallback(), ImageFillCallback(model, showcase_images, mask_generator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">breezy-dawn-26</strong> at: <a href=\"https://wandb.ai/put_dl_team/cv3-ii-ae-unet/runs/w3zt5pp8\" target=\"_blank\">https://wandb.ai/put_dl_team/cv3-ii-ae-unet/runs/w3zt5pp8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230119_213251-w3zt5pp8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "223b5715064e6337f4c6c5c31ba119f7f673243f3a7867c303e638162a937524"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
