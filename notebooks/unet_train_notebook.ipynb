{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import functools\n",
    "\n",
    "from src.display import showarray\n",
    "from src.mask import MaskGenerator\n",
    "from src.datagen import DatasetFillGenerator\n",
    "from src.augmenters import masked_channel_augmenter, masked_split_augmenter\n",
    "from src.builders.unet import UNETBuilder\n",
    "from src.builders.pcunet import PCUNETBuilder\n",
    "from src.loss import (\n",
    "    MaskedMAE, \n",
    "    MaskedGaussedSobelMAE, \n",
    "    GaussedSobelMAE,\n",
    "    SSIMLoss, \n",
    "    CombinedLoss\n",
    ")\n",
    "from src.metrics import dice_coef, ssim_coef\n",
    "from src.layers.pconv import PConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msbartekt\u001b[0m (\u001b[33mput_dl_team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sbart\\OneDrive - put.poznan.pl\\Semestr V\\Computer Vision\\Project 3\\notebooks\\wandb\\run-20230124_165938-8zwgvrhl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/put_dl_team/cv3B-ii-ae-unet/runs/8zwgvrhl\" target=\"_blank\">festive-kumquat-5</a></strong> to <a href=\"https://wandb.ai/put_dl_team/cv3B-ii-ae-unet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/put_dl_team/cv3B-ii-ae-unet\" target=\"_blank\">https://wandb.ai/put_dl_team/cv3B-ii-ae-unet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/put_dl_team/cv3B-ii-ae-unet/runs/8zwgvrhl\" target=\"_blank\">https://wandb.ai/put_dl_team/cv3B-ii-ae-unet/runs/8zwgvrhl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 1,\n",
    "  \"batch_size\": 16,\n",
    "  \"mask_gen_degree\": \"HEAVY\",\n",
    "  \"mask_gen_min_width\": 5,\n",
    "  \"mask_gen_max_width\": 12,\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"use_partial_conv\": True\n",
    "}\n",
    "model_params = {\n",
    "  \"n_filters\": 32,\n",
    "  \"n_blocks\": 3,\n",
    "  \"n_convs\": 1,\n",
    "  \"activation\": \"elu\",\n",
    "  \"dropout_rate\": 0.4,\n",
    "}\n",
    "loss_dict = {\n",
    "  \"masked_mae\": MaskedMAE(),\n",
    "  \"masked_gaussed_sobel_mae\": MaskedGaussedSobelMAE(),\n",
    "  \"gaussed_sobel_mae\": GaussedSobelMAE(),\n",
    "  \"mae\": tf.keras.losses.MeanAbsoluteError(),\n",
    "  \"ssim\": SSIMLoss(),\n",
    "}\n",
    "loss_weights = {\n",
    "  \"masked_mae\": 0.0,\n",
    "  \"masked_gaussed_sobel_mae\": 0.0,\n",
    "  \"gaussed_sobel_mae\": 0.0,\n",
    "  \"mae\": 1.0,\n",
    "  \"ssim\": 0.0,\n",
    "}\n",
    "\n",
    "loss_config = {key: (loss_fn, loss_weights[key]) for key, loss_fn in loss_dict.items()}\n",
    "\n",
    "config.update({f\"unet_{key}\": val for key, val in model_params.items()})\n",
    "config.update({f\"loss_{key}_weight\": val for key, val in loss_weights.items()})\n",
    "wandb.init(project=\"cv3B-ii-ae-unet\", entity=\"put_dl_team\", config=config)\n",
    "\n",
    "IMAGE_SIZE = (256, 256)\n",
    "CHANNELS = 3\n",
    "effective_channels = CHANNELS + 1\n",
    "if wandb.config[\"use_partial_conv\"]:\n",
    "  effective_channels = CHANNELS\n",
    "\n",
    "IM_SHAPE = IMAGE_SIZE + (effective_channels,)\n",
    "\n",
    "BATCH_SIZE = wandb.config[\"batch_size\"]\n",
    "MASK_GEN_PARAM = {\n",
    "    \"degree\": wandb.config[\"mask_gen_degree\"],\n",
    "    \"min_width\": wandb.config[\"mask_gen_min_width\"],\n",
    "    \"max_width\": wandb.config[\"mask_gen_max_width\"],\n",
    "}\n",
    "\n",
    "mask_generator = MaskGenerator(*IMAGE_SIZE, CHANNELS, **MASK_GEN_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 128 files belonging to 1 classes.\n",
      "Using 116 files for training.\n",
      "Using 12 files for validation.\n",
      "Found 141 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "def scale(tensor: tf.Tensor, divisor: float = 255.0) -> tf.Tensor:\n",
    "    return tensor / divisor\n",
    "\n",
    "def recast_to_image(tensor: tf.Tensor) -> np.ndarray:\n",
    "    return tf.cast(tensor[:, :, :3] * 255, tf.uint8).numpy()\n",
    "\n",
    "\n",
    "ds_train, ds_valid = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"../data/supersmall\", label_mode=None, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
    "    shuffle=True, seed=42, validation_split=0.1, subset=\"both\",\n",
    ")\n",
    "ds_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"../data/test\", label_mode=None, image_size=IMAGE_SIZE, batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "ds_train = ds_train.map(scale)\n",
    "ds_valid = ds_valid.map(scale)\n",
    "ds_test = ds_test.map(scale)\n",
    "\n",
    "for batch in ds_valid.take(1):\n",
    "    showcase_images = batch[:5]\n",
    "\n",
    "dataset_image_augmenter = functools.partial(masked_channel_augmenter, mask_generator=mask_generator)\n",
    "builder_class = UNETBuilder\n",
    "if wandb.config[\"use_partial_conv\"]:\n",
    "    if \"n_convs\" in model_params:\n",
    "        del model_params[\"n_convs\"]\n",
    "    model_params[\"pconv_class\"] = PConv2D\n",
    "    dataset_image_augmenter = functools.partial(masked_split_augmenter, mask_generator=mask_generator)\n",
    "    builder_class = PCUNETBuilder\n",
    "\n",
    "\n",
    "class ImageFillCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, showcase_images, augmenter):\n",
    "        self.model = model\n",
    "        self.input_data, self.showcase_images = augmenter(showcase_images)\n",
    "        self.masked_images = self.input_data\n",
    "        if len(self.masked_images) == 2:\n",
    "            self.masks, self.masked_images = self.input_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        nn_filled = self.model.predict(self.input_data)\n",
    "        all_joint = []\n",
    "        for i in range(5):\n",
    "            masked = recast_to_image(self.masked_images[i])\n",
    "            original_image = recast_to_image(self.showcase_images[i])\n",
    "            filled_image = recast_to_image(nn_filled[i])\n",
    "            joint = np.concatenate([masked, original_image, filled_image], axis=1)\n",
    "            all_joint.append(joint)\n",
    "        all_joint = np.concatenate(all_joint, axis=0)\n",
    "        wandb.log({\"sample_fill\": wandb.Image(all_joint)})\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "train_generator = DatasetFillGenerator(ds_train, dataset_image_augmenter)\n",
    "valid_generator = DatasetFillGenerator(ds_valid, dataset_image_augmenter)\n",
    "test_generator = DatasetFillGenerator(ds_test, dataset_image_augmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " p_conv2d_24 (PConv2D)          ((None, 256, 256, 3  1760        ['input_5[0][0]',                \n",
      "                                2),                               'input_6[0][0]']                \n",
      "                                 (None, 256, 256, 3                                               \n",
      "                                2))                                                               \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 256, 256, 32  0           ['p_conv2d_24[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " p_conv2d_25 (PConv2D)          ((None, 128, 128, 3  18464       ['dropout_6[0][0]',              \n",
      "                                2),                               'p_conv2d_24[0][1]']            \n",
      "                                 (None, 128, 128, 3                                               \n",
      "                                2))                                                               \n",
      "                                                                                                  \n",
      " p_conv2d_26 (PConv2D)          ((None, 128, 128, 6  36928       ['p_conv2d_25[0][0]',            \n",
      "                                4),                               'p_conv2d_25[0][1]']            \n",
      "                                 (None, 128, 128, 6                                               \n",
      "                                4))                                                               \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128, 128, 64  0           ['p_conv2d_26[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " p_conv2d_27 (PConv2D)          ((None, 64, 64, 64)  73792       ['dropout_7[0][0]',              \n",
      "                                , (None, 64, 64, 64               'p_conv2d_26[0][1]']            \n",
      "                                ))                                                                \n",
      "                                                                                                  \n",
      " p_conv2d_28 (PConv2D)          ((None, 64, 64, 128  147584      ['p_conv2d_27[0][0]',            \n",
      "                                ),                                'p_conv2d_27[0][1]']            \n",
      "                                 (None, 64, 64, 128                                               \n",
      "                                ))                                                                \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 64, 64, 128)  0           ['p_conv2d_28[0][0]']            \n",
      "                                                                                                  \n",
      " p_conv2d_29 (PConv2D)          ((None, 32, 32, 128  295040      ['dropout_8[0][0]',              \n",
      "                                ),                                'p_conv2d_28[0][1]']            \n",
      "                                 (None, 32, 32, 128                                               \n",
      "                                ))                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_12 (UpSampling2D  (None, 64, 64, 128)  0          ['p_conv2d_29[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_13 (UpSampling2D  (None, 64, 64, 128)  0          ['p_conv2d_29[0][1]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 64, 64, 256)  0           ['dropout_8[0][0]',              \n",
      "                                                                  'up_sampling2d_12[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_13 (Concatenate)   (None, 64, 64, 256)  0           ['p_conv2d_28[0][1]',            \n",
      "                                                                  'up_sampling2d_13[0][0]']       \n",
      "                                                                                                  \n",
      " p_conv2d_30 (PConv2D)          ((None, 64, 64, 128  589952      ['concatenate_12[0][0]',         \n",
      "                                ),                                'concatenate_13[0][0]']         \n",
      "                                 (None, 64, 64, 128                                               \n",
      "                                ))                                                                \n",
      "                                                                                                  \n",
      " p_conv2d_31 (PConv2D)          ((None, 64, 64, 64)  147520      ['p_conv2d_30[0][0]',            \n",
      "                                , (None, 64, 64, 64               'p_conv2d_30[0][1]']            \n",
      "                                ))                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_14 (UpSampling2D  (None, 128, 128, 64  0          ['p_conv2d_31[0][0]']            \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_15 (UpSampling2D  (None, 128, 128, 64  0          ['p_conv2d_31[0][1]']            \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_14 (Concatenate)   (None, 128, 128, 12  0           ['dropout_7[0][0]',              \n",
      "                                8)                                'up_sampling2d_14[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_15 (Concatenate)   (None, 128, 128, 12  0           ['p_conv2d_26[0][1]',            \n",
      "                                8)                                'up_sampling2d_15[0][0]']       \n",
      "                                                                                                  \n",
      " p_conv2d_32 (PConv2D)          ((None, 128, 128, 6  147520      ['concatenate_14[0][0]',         \n",
      "                                4),                               'concatenate_15[0][0]']         \n",
      "                                 (None, 128, 128, 6                                               \n",
      "                                4))                                                               \n",
      "                                                                                                  \n",
      " p_conv2d_33 (PConv2D)          ((None, 128, 128, 3  36896       ['p_conv2d_32[0][0]',            \n",
      "                                2),                               'p_conv2d_32[0][1]']            \n",
      "                                 (None, 128, 128, 3                                               \n",
      "                                2))                                                               \n",
      "                                                                                                  \n",
      " up_sampling2d_16 (UpSampling2D  (None, 256, 256, 32  0          ['p_conv2d_33[0][0]']            \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_17 (UpSampling2D  (None, 256, 256, 32  0          ['p_conv2d_33[0][1]']            \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_16 (Concatenate)   (None, 256, 256, 64  0           ['dropout_6[0][0]',              \n",
      "                                )                                 'up_sampling2d_16[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_17 (Concatenate)   (None, 256, 256, 64  0           ['p_conv2d_24[0][1]',            \n",
      "                                )                                 'up_sampling2d_17[0][0]']       \n",
      "                                                                                                  \n",
      " p_conv2d_34 (PConv2D)          ((None, 256, 256, 3  36896       ['concatenate_16[0][0]',         \n",
      "                                2),                               'concatenate_17[0][0]']         \n",
      "                                 (None, 256, 256, 3                                               \n",
      "                                2))                                                               \n",
      "                                                                                                  \n",
      " p_conv2d_35 (PConv2D)          ((None, 256, 256, 1  9232        ['p_conv2d_34[0][0]',            \n",
      "                                6),                               'p_conv2d_34[0][1]']            \n",
      "                                 (None, 256, 256, 1                                               \n",
      "                                6))                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 256, 3)  435         ['p_conv2d_35[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,542,019\n",
      "Trainable params: 1,542,019\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "builder = builder_class(IM_SHAPE, IM_SHAPE, **model_params)\n",
    "model = builder.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CombinedLoss(loss_config)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=wandb.config[\"learning_rate\"]),\n",
    "    loss=loss,\n",
    "    metrics=[dice_coef, ssim_coef],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 0.2553 - dice_coef: 0.4592 - ssim_coef: 0.3357 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\sbart\\OneDrive - put.poznan.pl\\Semestr V\\Computer Vision\\Project 3\\notebooks\\wandb\\run-20230124_165938-8zwgvrhl\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\sbart\\OneDrive - put.poznan.pl\\Semestr V\\Computer Vision\\Project 3\\notebooks\\wandb\\run-20230124_165938-8zwgvrhl\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (c:\\Users\\sbart\\OneDrive - put.poznan.pl\\Semestr V\\Computer Vision\\Project 3\\notebooks\\wandb\\run-20230124_165938-8zwgvrhl\\files\\model-best)... Done. 0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "8/8 [==============================] - 185s 20s/step - loss: 0.2553 - dice_coef: 0.4592 - ssim_coef: 0.3357 - val_loss: 0.2621 - val_dice_coef: 0.4696 - val_ssim_coef: 0.3518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20219741570>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator, \n",
    "    epochs=wandb.config[\"epochs\"], \n",
    "    validation_data=valid_generator, \n",
    "    callbacks=[\n",
    "        wandb.keras.WandbCallback(), \n",
    "        ImageFillCallback(model, showcase_images, dataset_image_augmenter)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 48s 336ms/step - loss: 0.2460 - dice_coef: 0.4498 - ssim_coef: 0.3201\n"
     ]
    }
   ],
   "source": [
    "test_result = model.evaluate(test_generator)\n",
    "wandb.log({\"test_loss\": test_result[0], \"test_dice\": test_result[1], \"test_ssim\": test_result[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 345ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 257ms/step\n",
      "1/1 [==============================] - 0s 241ms/step\n"
     ]
    }
   ],
   "source": [
    "test_mask_generator = MaskGenerator(*IMAGE_SIZE, CHANNELS, degree=\"HEAVY\", min_width=10, max_width=24)\n",
    "\n",
    "test_generator = DatasetFillGenerator(\n",
    "    ds_test, \n",
    "    dataset_image_augmenter,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "all_joint = []\n",
    "for i in range(5):\n",
    "    input_data, showcase_image = test_generator[i]\n",
    "    nn_filled = model.predict(input_data)\n",
    "    masked_image = input_data\n",
    "    if len(input_data) == 2:\n",
    "        masked_image = input_data[0]\n",
    "    masked = recast_to_image(masked_image[0])\n",
    "    original_image = recast_to_image(showcase_image[0])\n",
    "    filled_image = recast_to_image(nn_filled[0])\n",
    "    joint = np.concatenate([masked, original_image, filled_image], axis=1)\n",
    "    all_joint.append(joint)\n",
    "all_joint = np.concatenate(all_joint, axis=0)\n",
    "wandb.log({\"test_fill_result\": wandb.Image(all_joint)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Control-C detected -- Run data was not synced\n"
     ]
    }
   ],
   "source": [
    "wandb.finish(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a0764124d9b0ac1585fac6f6636ff3c06a49bfb47c9dbbda49bea898317cf46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
