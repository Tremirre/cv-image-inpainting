{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import functools\n",
    "\n",
    "from src.display import showarray\n",
    "from src.mask import MaskGenerator\n",
    "from src.datagen import DatasetFillGenerator\n",
    "from src.augmenters import masked_channel_augmenter, masked_split_augmenter\n",
    "from src.builders.unet import UNETBuilder\n",
    "from src.builders.pcunet import PCUNETBuilder\n",
    "from src.loss import (\n",
    "    MaskedMAE, \n",
    "    MaskedGaussedSobelMAE, \n",
    "    GaussedSobelMAE,\n",
    "    SSIMLoss, \n",
    "    CombinedLoss\n",
    ")\n",
    "from src.metrics import dice_coef, ssim_coef\n",
    "from src.layers.pconv import PConv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msbartekt\u001b[0m (\u001b[33mput_dl_team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230125_145207-he8db57w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/put_dl_team/cv3B-ii-ae-unet/runs/he8db57w\" target=\"_blank\">flashing-lantern-22</a></strong> to <a href=\"https://wandb.ai/put_dl_team/cv3B-ii-ae-unet\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/put_dl_team/cv3B-ii-ae-unet\" target=\"_blank\">https://wandb.ai/put_dl_team/cv3B-ii-ae-unet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/put_dl_team/cv3B-ii-ae-unet/runs/he8db57w\" target=\"_blank\">https://wandb.ai/put_dl_team/cv3B-ii-ae-unet/runs/he8db57w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = {\n",
    "  \"learning_rate\": 0.002,\n",
    "  \"epochs\": 16,\n",
    "  \"batch_size\": 8,\n",
    "  \"mask_gen_degree\": \"HEAVY\",\n",
    "  \"mask_gen_min_width\": 5,\n",
    "  \"mask_gen_max_width\": 12,\n",
    "  \"use_partial_conv\": True\n",
    "}\n",
    "model_params = {\n",
    "  \"n_filters\": 16,\n",
    "  \"n_blocks\": 2,\n",
    "  \"n_convs\": 1,\n",
    "  \"activation\": \"gelu\",\n",
    "  \"dropout_rate\": 0.2,\n",
    "}\n",
    "loss_dict = {\n",
    "  \"masked_mae\": MaskedMAE(),\n",
    "  \"masked_gaussed_sobel_mae\": MaskedGaussedSobelMAE(),\n",
    "  \"gaussed_sobel_mae\": GaussedSobelMAE(),\n",
    "  \"mae\": tf.keras.losses.MeanAbsoluteError(),\n",
    "  \"ssim\": SSIMLoss(),\n",
    "}\n",
    "loss_weights = {\n",
    "  \"masked_mae\": 0,\n",
    "  \"masked_gaussed_sobel_mae\": 0,\n",
    "  \"gaussed_sobel_mae\": 0.2,\n",
    "  \"mae\": 0.4,\n",
    "  \"ssim\": 0.4,\n",
    "}\n",
    "\n",
    "loss_config = {key: (loss_fn, loss_weights[key]) for key, loss_fn in loss_dict.items() if loss_weights[key] > 0}\n",
    "\n",
    "config.update({f\"unet_{key}\": val for key, val in model_params.items()})\n",
    "config.update({f\"loss_{key}_weight\": val for key, val in loss_weights.items()})\n",
    "wandb.init(project=\"cv3B-ii-ae-unet\", entity=\"put_dl_team\", config=config)\n",
    "\n",
    "IMAGE_SIZE = (256, 256)\n",
    "CHANNELS = 3\n",
    "effective_channels = CHANNELS + 1\n",
    "if wandb.config[\"use_partial_conv\"]:\n",
    "  effective_channels = CHANNELS\n",
    "\n",
    "IM_SHAPE = IMAGE_SIZE + (effective_channels,)\n",
    "\n",
    "BATCH_SIZE = wandb.config[\"batch_size\"]\n",
    "MASK_GEN_PARAM = {\n",
    "    \"degree\": wandb.config[\"mask_gen_degree\"],\n",
    "    \"min_width\": wandb.config[\"mask_gen_min_width\"],\n",
    "    \"max_width\": wandb.config[\"mask_gen_max_width\"],\n",
    "}\n",
    "\n",
    "mask_generator = MaskGenerator(*IMAGE_SIZE, CHANNELS, **MASK_GEN_PARAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2188 files belonging to 1 classes.\n",
      "Using 1970 files for training.\n",
      "Using 218 files for validation.\n",
      "Found 141 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "def scale(tensor: tf.Tensor, divisor: float = 255.0) -> tf.Tensor:\n",
    "    return tensor / divisor\n",
    "\n",
    "def recast_to_image(tensor: tf.Tensor) -> np.ndarray:\n",
    "    return tf.cast(tensor[:, :, :3] * 255, tf.uint8).numpy()\n",
    "\n",
    "\n",
    "ds_train, ds_valid = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"../data/1-8size\", label_mode=None, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
    "    shuffle=True, seed=42, validation_split=0.1, subset=\"both\",\n",
    ")\n",
    "ds_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"../data/test\", label_mode=None, image_size=IMAGE_SIZE, batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "ds_train = ds_train.map(scale)\n",
    "ds_valid = ds_valid.map(scale)\n",
    "ds_test = ds_test.map(scale)\n",
    "\n",
    "for batch in ds_valid.take(1):\n",
    "    showcase_images = batch[:5]\n",
    "\n",
    "dataset_image_augmenter = functools.partial(masked_channel_augmenter, mask_generator=mask_generator)\n",
    "builder_class = UNETBuilder\n",
    "if wandb.config[\"use_partial_conv\"]:\n",
    "    if \"n_convs\" in model_params:\n",
    "        del model_params[\"n_convs\"]\n",
    "    model_params[\"pconv_class\"] = PConv2D\n",
    "    dataset_image_augmenter = functools.partial(masked_split_augmenter, mask_generator=mask_generator)\n",
    "    builder_class = PCUNETBuilder\n",
    "\n",
    "\n",
    "class ImageFillCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, showcase_images, augmenter):\n",
    "        self.model = model\n",
    "        self.input_data, self.showcase_images = augmenter(showcase_images)\n",
    "        self.masked_images = self.input_data\n",
    "        if len(self.masked_images) == 2:\n",
    "            self.masked_images, self.masks = self.input_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        nn_filled = self.model.predict(self.input_data)\n",
    "        all_joint = []\n",
    "        for i in range(5):\n",
    "            masked = recast_to_image(self.masked_images[i])\n",
    "            original_image = recast_to_image(self.showcase_images[i])\n",
    "            filled_image = recast_to_image(nn_filled[i])\n",
    "            joint = np.concatenate([masked, original_image, filled_image], axis=1)\n",
    "            all_joint.append(joint)\n",
    "        all_joint = np.concatenate(all_joint, axis=0)\n",
    "        wandb.log({\"sample_fill\": wandb.Image(all_joint)})\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "train_generator = DatasetFillGenerator(ds_train, dataset_image_augmenter)\n",
    "valid_generator = DatasetFillGenerator(ds_valid, dataset_image_augmenter)\n",
    "test_generator = DatasetFillGenerator(ds_test, dataset_image_augmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " p_conv2d (PConv2D)             ((None, 256, 256, 1  880         ['input_1[0][0]',                \n",
      "                                6),                               'input_2[0][0]']                \n",
      "                                 (None, 256, 256, 1                                               \n",
      "                                6))                                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256, 256, 16  0           ['p_conv2d[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " p_conv2d_1 (PConv2D)           ((None, 128, 128, 1  4624        ['dropout[0][0]',                \n",
      "                                6),                               'p_conv2d[0][1]']               \n",
      "                                 (None, 128, 128, 1                                               \n",
      "                                6))                                                               \n",
      "                                                                                                  \n",
      " p_conv2d_2 (PConv2D)           ((None, 128, 128, 3  9248        ['p_conv2d_1[0][0]',             \n",
      "                                2),                               'p_conv2d_1[0][1]']             \n",
      "                                 (None, 128, 128, 3                                               \n",
      "                                2))                                                               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128, 128, 32  0           ['p_conv2d_2[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " p_conv2d_3 (PConv2D)           ((None, 64, 64, 32)  18464       ['dropout_1[0][0]',              \n",
      "                                , (None, 64, 64, 32               'p_conv2d_2[0][1]']             \n",
      "                                ))                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 128, 128, 32  0           ['p_conv2d_3[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 32  0          ['p_conv2d_3[0][1]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 128, 64  0           ['dropout_1[0][0]',              \n",
      "                                )                                 'up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 64  0           ['p_conv2d_2[0][1]',             \n",
      "                                )                                 'up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " p_conv2d_4 (PConv2D)           ((None, 128, 128, 3  36896       ['concatenate[0][0]',            \n",
      "                                2),                               'concatenate_1[0][0]']          \n",
      "                                 (None, 128, 128, 3                                               \n",
      "                                2))                                                               \n",
      "                                                                                                  \n",
      " p_conv2d_5 (PConv2D)           ((None, 128, 128, 1  9232        ['p_conv2d_4[0][0]',             \n",
      "                                6),                               'p_conv2d_4[0][1]']             \n",
      "                                 (None, 128, 128, 1                                               \n",
      "                                6))                                                               \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 16  0          ['p_conv2d_5[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 16  0          ['p_conv2d_5[0][1]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 32  0           ['dropout[0][0]',                \n",
      "                                )                                 'up_sampling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 32  0           ['p_conv2d[0][1]',               \n",
      "                                )                                 'up_sampling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " p_conv2d_6 (PConv2D)           ((None, 256, 256, 1  9232        ['concatenate_2[0][0]',          \n",
      "                                6),                               'concatenate_3[0][0]']          \n",
      "                                 (None, 256, 256, 1                                               \n",
      "                                6))                                                               \n",
      "                                                                                                  \n",
      " p_conv2d_7 (PConv2D)           ((None, 256, 256, 8  2312        ['p_conv2d_6[0][0]',             \n",
      "                                ),                                'p_conv2d_6[0][1]']             \n",
      "                                 (None, 256, 256, 8                                               \n",
      "                                ))                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 3)  219         ['p_conv2d_7[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 91,107\n",
      "Trainable params: 91,107\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "builder = builder_class(IM_SHAPE, IM_SHAPE, **model_params)\n",
    "model = builder.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = CombinedLoss(loss_config)\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=wandb.config[\"learning_rate\"]),\n",
    "    loss=loss,\n",
    "    metrics=[dice_coef, ssim_coef],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.2856 - dice_coef: 0.5320 - ssim_coef: 0.4919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230125_145207-he8db57w\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230125_145207-he8db57w\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230125_145207-he8db57w\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 736ms/step\n",
      "247/247 [==============================] - 191s 740ms/step - loss: 0.2856 - dice_coef: 0.5320 - ssim_coef: 0.4919 - val_loss: 0.2254 - val_dice_coef: 0.5778 - val_ssim_coef: 0.5884\n",
      "Epoch 2/16\n",
      "247/247 [==============================] - ETA: 0s - loss: 0.2169 - dice_coef: 0.5810 - ssim_coef: 0.6065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 9). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230125_145207-he8db57w\\files\\model-best\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230125_145207-he8db57w\\files\\model-best\\assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230125_145207-he8db57w\\files\\model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "247/247 [==============================] - 298s 1s/step - loss: 0.2169 - dice_coef: 0.5810 - ssim_coef: 0.6065 - val_loss: 0.1746 - val_dice_coef: 0.5856 - val_ssim_coef: 0.6822\n",
      "Epoch 3/16\n",
      "106/247 [===========>..................] - ETA: 2:43 - loss: 0.1737 - dice_coef: 0.5972 - ssim_coef: 0.6859"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m     train_generator, \n\u001b[0;32m      3\u001b[0m     epochs\u001b[39m=\u001b[39;49mwandb\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[0;32m      4\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalid_generator, \n\u001b[0;32m      5\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      6\u001b[0m         wandb\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mWandbCallback(), \n\u001b[0;32m      7\u001b[0m         ImageFillCallback(model, showcase_images, dataset_image_augmenter)\n\u001b[0;32m      8\u001b[0m     ]\n\u001b[0;32m      9\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Bartosz\\.conda\\envs\\deep\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator, \n",
    "    epochs=wandb.config[\"epochs\"], \n",
    "    validation_data=valid_generator, \n",
    "    callbacks=[\n",
    "        wandb.keras.WandbCallback(), \n",
    "        ImageFillCallback(model, showcase_images, dataset_image_augmenter)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "callback = ImageFillCallback(model, showcase_images, dataset_image_augmenter)\n",
    "callback.on_epoch_end(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 11s 69ms/step - loss: 0.0309 - dice_coef: 0.6388 - ssim_coef: 0.9387\n"
     ]
    }
   ],
   "source": [
    "test_result = model.evaluate(test_generator)\n",
    "wandb.log({\"test_loss\": test_result[0], \"test_dice\": test_result[1], \"test_ssim\": test_result[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "test_mask_generator = MaskGenerator(*IMAGE_SIZE, CHANNELS, degree=\"HEAVY\", min_width=10, max_width=24)\n",
    "\n",
    "test_generator = DatasetFillGenerator(\n",
    "    ds_test, \n",
    "    dataset_image_augmenter,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "all_joint = []\n",
    "for i in range(5):\n",
    "    input_data, showcase_image = test_generator[i]\n",
    "    nn_filled = model.predict(input_data)\n",
    "    masked_image = input_data\n",
    "    if len(input_data) == 2:\n",
    "        masked_image = input_data[0]\n",
    "    masked = recast_to_image(masked_image[0])\n",
    "    original_image = recast_to_image(showcase_image[0])\n",
    "    filled_image = recast_to_image(nn_filled[0])\n",
    "    joint = np.concatenate([masked, original_image, filled_image], axis=1)\n",
    "    all_joint.append(joint)\n",
    "all_joint = np.concatenate(all_joint, axis=0)\n",
    "wandb.log({\"test_fill_result\": wandb.Image(all_joint)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230125_132348-zumeq7sa\\files\\model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Bartosz\\PycharmProjects\\CV3_PROJECT\\cv-image-inpainting\\notebooks\\wandb\\run-20230125_132348-zumeq7sa\\files\\model\\assets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dice_coef</td><td>▁▆▇▇▇██████▇▇██▇</td></tr><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>loss</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ssim_coef</td><td>▁▆▇▇▇▇██████████</td></tr><tr><td>test_dice</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_ssim</td><td>▁</td></tr><tr><td>val_dice_coef</td><td>▃▁▂▆▇▄▄▁▅▄▄▆▆█▆▅</td></tr><tr><td>val_loss</td><td>█▆▅▄▄▃▂▂▂▂▁▂▂▁▁▁</td></tr><tr><td>val_ssim_coef</td><td>▁▃▅▅▅▆▇▇▇▇█▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>15</td></tr><tr><td>best_val_loss</td><td>0.03014</td></tr><tr><td>dice_coef</td><td>0.64636</td></tr><tr><td>epoch</td><td>15</td></tr><tr><td>loss</td><td>0.03098</td></tr><tr><td>ssim_coef</td><td>0.93824</td></tr><tr><td>test_dice</td><td>0.63876</td></tr><tr><td>test_loss</td><td>0.03092</td></tr><tr><td>test_ssim</td><td>0.93865</td></tr><tr><td>val_dice_coef</td><td>0.64524</td></tr><tr><td>val_loss</td><td>0.03014</td></tr><tr><td>val_ssim_coef</td><td>0.93993</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glittering-bao-19</strong> at: <a href=\"https://wandb.ai/put_dl_team/cv3B-ii-ae-unet/runs/zumeq7sa\" target=\"_blank\">https://wandb.ai/put_dl_team/cv3B-ii-ae-unet/runs/zumeq7sa</a><br/>Synced 6 W&B file(s), 18 media file(s), 52 artifact file(s) and 5 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230125_132348-zumeq7sa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.save(os.path.join(wandb.run.dir, \"model\"))\n",
    "wandb.finish(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 | packaged by conda-forge | (main, Mar 30 2022, 08:38:02) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8a0764124d9b0ac1585fac6f6636ff3c06a49bfb47c9dbbda49bea898317cf46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
